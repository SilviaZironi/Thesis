{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ec3275",
   "metadata": {},
   "source": [
    "# Bayesian cutoff analysis for Triton binding energy (LO/NLO/N2LO)\n",
    "\n",
    "This notebook:\n",
    "1. Parses TRITON output files grouped by chiral order (LO, NLO, N2LO) and cutoff values \\(R\\).\n",
    "2. Estimates EFT uncertainty at each order from cutoff spread.\n",
    "3. Computes discrete Bayesian posterior over \\(R\\) with a Gaussian likelihood.\n",
    "4. Performs Bayesian Model Averaging (BMA) across cutoffs.\n",
    "5. Produces plots and exports tables for the thesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64eb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c289aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /mnt/c/Users/silvi/Desktop/TESI3/results_cutoff\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder that contains: cutoff_LO/, cutof_NLO/, cutoff_N2LO/\n",
    "BASE_DIR = Path(r\"results_cutoff\")  \n",
    "\n",
    "# Experimental value \n",
    "E_EXP = -8.482 #MeV\n",
    "\n",
    "# Experimental uncertainty. Usually negligible vs EFT/systematics.\n",
    "SIGMA_EXP = 0.01 #MeV\n",
    "\n",
    "# Folder name mapping \n",
    "ORDER_MAP = {\n",
    "    \"cutoff_lo\": \"LO\",\n",
    "    \"cutoff_nlo\": \"NLO\",\n",
    "    \"cutoff_n2lo\": \"N2LO\",\n",
    "}\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c27eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_order_from_path(p: Path) -> str:\n",
    "    parts = [x.lower() for x in p.parts]\n",
    "    for part in reversed(parts):\n",
    "        if part in ORDER_MAP:\n",
    "            return ORDER_MAP[part]\n",
    "    raise ValueError(f\"Cannot infer order from path: {p}\")\n",
    "\n",
    "\n",
    "def infer_R_from_filename(name: str) -> float:\n",
    "    \"\"\"\n",
    "    Robust inference of R from filename.\n",
    "    Supports:\n",
    "      - R08 -> 0.8\n",
    "      - R10 -> 1.0\n",
    "      - R0.8 -> 0.8\n",
    "      - any '0.8' substring\n",
    "    \"\"\"\n",
    "    s = name.lower()\n",
    "\n",
    "    # R08 / R10 / R12 pattern\n",
    "    m = re.search(r\"r(\\d{2})\", s)\n",
    "    if m:\n",
    "        two = int(m.group(1))\n",
    "        return two / 10.0\n",
    "\n",
    "    # R0.8 / R1.2 pattern\n",
    "    m = re.search(r\"r(\\d+\\.\\d+)\", s)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "\n",
    "    # plain 0.8 pattern\n",
    "    m = re.search(r\"(\\d+\\.\\d+)\", s)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "\n",
    "    raise ValueError(f\"Cannot infer R from filename: {name}\")\n",
    "\n",
    "\n",
    "def read_triton_energy(file_path: Path) -> float:\n",
    "    \"\"\"\n",
    "    Extract triton binding energy from a .dat file\n",
    "    \"\"\"\n",
    "    text = file_path.read_text(errors=\"ignore\")\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # float regex supports Fortran D exponents too\n",
    "    float_re = r\"[-+]?\\d*\\.\\d+(?:[eEdD][-+]?\\d+)?|[-+]?\\d+(?:[eEdD][-+]?\\d+)?\"\n",
    "\n",
    "    # targeted line search\n",
    "    for line in lines[::-1]:\n",
    "        low = line.lower()\n",
    "        if (\"triton\" in low) or (\"3h\" in low) or (\"binding\" in low):\n",
    "            nums = re.findall(float_re, line)\n",
    "            if nums:\n",
    "                return float(nums[-1].replace(\"D\", \"E\").replace(\"d\", \"E\"))\n",
    "\n",
    "    # fallback: last number in file\n",
    "    nums = re.findall(float_re, text)\n",
    "    if not nums:\n",
    "        raise ValueError(f\"No numeric values found in {file_path}\")\n",
    "    return float(nums[-1].replace(\"D\", \"E\").replace(\"d\", \"E\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afa35c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'R'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4101/2650179935.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No .dat files found under {BASE_DIR.resolve()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"R\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"R (fm)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"E_triton (MeV)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/silvi/Desktop/TESI3/.venv/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7190\u001b[0m                 \u001b[0;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m                 \u001b[0;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7192\u001b[0m             )\n\u001b[1;32m   7193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7194\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7196\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/silvi/Desktop/TESI3/.venv/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m-> 7194\u001b[0;31m         \u001b[0;34m...\u001b[0m     \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_natsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/silvi/Desktop/TESI3/.venv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1910\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'R'"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fp in BASE_DIR.rglob(\"*.dat\"):\n",
    "    order = infer_order_from_path(fp)\n",
    "    R = infer_R_from_filename(fp.name)\n",
    "    E = read_triton_energy(fp)\n",
    "    rows.append({\"order\": order, \"R\": R, \"E_triton (MeV)\": E, \"file\": str(fp)})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    raise RuntimeError(f\"No .dat files found under {BASE_DIR.resolve()}\")\n",
    "\n",
    "df = df.sort_values([\"order\", \"R\"]).reset_index(drop=True)\n",
    "\n",
    "df[[\"order\", \"R\", \"E_triton (MeV)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c088d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check we have 5 cutoffs per order (expected)\n",
    "counts = df.groupby(\"order\")[\"R\"].count()\n",
    "display(counts)\n",
    "\n",
    "# Check unique R values\n",
    "display(df.groupby(\"order\")[\"R\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "eft = (\n",
    "    df.groupby(\"order\")[\"E_triton\"]\n",
    "      .std(ddof=1)\n",
    "      .reset_index()\n",
    "      .rename(columns={\"E_triton\": \"sigma_eft\"})\n",
    ")\n",
    "\n",
    "df = df.merge(eft, on=\"order\", how=\"left\")\n",
    "df[\"sigma_tot\"] = np.sqrt(SIGMA_EXP**2 + df[\"sigma_eft\"]**2)\n",
    "\n",
    "eft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875248ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"logL\"] = -0.5 * (df[\"E_triton\"] - E_EXP)**2 / (df[\"sigma_tot\"]**2)\n",
    "df[\"posterior_R\"] = 0.0\n",
    "\n",
    "for order in df[\"order\"].unique():\n",
    "    m = df[\"order\"] == order\n",
    "    logL = df.loc[m, \"logL\"].to_numpy()\n",
    "\n",
    "    # uniform prior over available cutoffs\n",
    "    w = np.exp(logL - logL.max())\n",
    "    df.loc[m, \"posterior_R\"] = w / w.sum()\n",
    "\n",
    "df[[\"order\", \"R\", \"E_triton\", \"sigma_eft\", \"posterior_R\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_rows = []\n",
    "for order in df[\"order\"].unique():\n",
    "    sub = df[df[\"order\"] == order]\n",
    "    w = sub[\"posterior_R\"].to_numpy()\n",
    "    E = sub[\"E_triton\"].to_numpy()\n",
    "\n",
    "    mean = float(np.sum(w * E))\n",
    "    var = float(np.sum(w * (E - mean)**2))\n",
    "    sd = float(np.sqrt(var))\n",
    "\n",
    "    bma_rows.append({\"order\": order, \"E_mean\": mean, \"E_sd\": sd})\n",
    "\n",
    "bma = pd.DataFrame(bma_rows)\n",
    "\n",
    "# Force order ordering LO, NLO, N2LO\n",
    "order_cat = pd.Categorical(bma[\"order\"], categories=[\"LO\", \"NLO\", \"N2LO\"], ordered=True)\n",
    "bma = bma.assign(order=order_cat).sort_values(\"order\").reset_index(drop=True)\n",
    "\n",
    "bma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.errorbar(bma[\"order\"], bma[\"E_mean\"], yerr=bma[\"E_sd\"], fmt=\"o\", capsize=5)\n",
    "plt.axhline(E_EXP, linestyle=\"--\")\n",
    "plt.ylabel(\"Triton binding energy [MeV]\")\n",
    "plt.xlabel(\"Chiral order\")\n",
    "plt.title(\"Bayesian model averaging over cutoff\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "\n",
    "for order in [\"LO\", \"NLO\", \"N2LO\"]:\n",
    "    sub = df[df[\"order\"] == order].sort_values(\"R\")\n",
    "    plt.plot(sub[\"R\"], sub[\"posterior_R\"], marker=\"o\", label=order)\n",
    "\n",
    "plt.xlabel(\"Cutoff R\")\n",
    "plt.ylabel(\"Posterior probability p(R | data)\")\n",
    "plt.title(\"Discrete posterior over cutoff\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"analysis_outputs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "df.to_csv(out_dir / \"parsed_triton_results.csv\", index=False)\n",
    "bma.to_csv(out_dir / \"bma_results.csv\", index=False)\n",
    "eft.to_csv(out_dir / \"eft_sigma_from_cutoff_spread.csv\", index=False)\n",
    "\n",
    "# Save figures\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.errorbar(bma[\"order\"], bma[\"E_mean\"], yerr=bma[\"E_sd\"], fmt=\"o\", capsize=5)\n",
    "plt.axhline(E_EXP, linestyle=\"--\")\n",
    "plt.ylabel(\"Triton binding energy [MeV]\")\n",
    "plt.xlabel(\"Chiral order\")\n",
    "plt.title(\"Bayesian model averaging over cutoff\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"bma_over_orders.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "for order in [\"LO\", \"NLO\", \"N2LO\"]:\n",
    "    sub = df[df[\"order\"] == order].sort_values(\"R\")\n",
    "    plt.plot(sub[\"R\"], sub[\"posterior_R\"], marker=\"o\", label=order)\n",
    "plt.xlabel(\"Cutoff R\")\n",
    "plt.ylabel(\"Posterior probability p(R | data)\")\n",
    "plt.title(\"Discrete posterior over cutoff\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"posterior_over_R.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved outputs in:\", out_dir.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
